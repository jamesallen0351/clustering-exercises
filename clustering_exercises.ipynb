{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5881bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering_exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3020d8d2",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "## Workflow\n",
    "\n",
    "### - Throughout the exercises, you may wish to do your work in a notebook, then transfer any functions you've created to an external python script.\n",
    "\n",
    "### - Keep in mind this is not always a linear process! You will probably be cycling between a notebook and an external python script frequently.\n",
    "\n",
    "### - Remember to run your code often to check for correct output and/or errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e201fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Exploring\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Visualizing\n",
    "# matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# default pandas decimal number display format\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "\n",
    "# import acquire\n",
    "# import summarize\n",
    "# import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39693f3b",
   "metadata": {},
   "source": [
    "# Zillow\n",
    "\n",
    "### For the following, iterate through the steps you would take to create functions: Write the code to do the following in a jupyter notebook, test it, convert to functions, then create the file to house those functions.\n",
    "\n",
    "### You will have a zillow.ipynb file and a helper file for each section in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8d1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d065f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a372bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00199243",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acquire' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3818d6daf47b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mallcustomer_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acquire' is not defined"
     ]
    }
   ],
   "source": [
    "df = acquire.get_mallcustomer_data()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e27147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql zillow example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8966a23",
   "metadata": {},
   "source": [
    "use zillow;\n",
    "\n",
    "/* are there duplicate parcels in the predictions table? */\n",
    "select parcelid, count(*)\n",
    "from predictions_2017\n",
    "group by parcelid\n",
    "having count(*) > 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f46a9",
   "metadata": {},
   "source": [
    "/* is this the case in the properties table? any duplicate parcels? */\n",
    "select parcelid, count(*)\n",
    "from properties_2017\n",
    "group by parcelid\n",
    "having count(*) > 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb42e52",
   "metadata": {},
   "source": [
    "/* we need the latest transaction date for each parcelid */\n",
    "select parcelid, max(transactiondate) as transactiondate\n",
    "from predictions_2017\n",
    "group by parcelid;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47709c4",
   "metadata": {},
   "source": [
    "/* how can we confirm this removed the duplicates */\n",
    "-- 1. how many rows did we start out with? \n",
    "select count(*) from predictions_2017; \n",
    "-- 77,614\n",
    "\n",
    "-- 2. how many rows do we have when we group by parcelid? \n",
    "select count(*) from \n",
    "(select parcelid, max(transactiondate) as transactiondate\n",
    "from predictions_2017\n",
    "group by parcelid\n",
    ") a\n",
    ";\n",
    "-- 77,414"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504e618",
   "metadata": {},
   "source": [
    "-- we want the info from properties table and the date and logerror from the predictions table\n",
    "\n",
    "-- 2. next I selected 2 columns from the primary table (properties_2017) and inner joined with the txn date subquery\n",
    "select \tprop.parcelid, \n",
    "\t\t\tprop.airconditioningtypeid,\n",
    "            ac.airconditioningdesc,-- 4. finally I did a left join with the airconditioning table to get the description. \n",
    "            txn.transactiondate, \n",
    "            pred.logerror -- 3.i joined with the predictions table again to get the log error that is associated with the parcel AND transaction date\n",
    "            -- (see join below labeled #3)\n",
    "from properties_2017 prop\n",
    "join \n",
    "\t(\n",
    "    -- 1. this is what i did first...create a dataset with each parcelid and their last transaction date. \n",
    "    select parcelid, max(transactiondate) as transactiondate\n",
    "\tfrom predictions_2017\n",
    "\tgroup by parcelid\n",
    "\t) as txn on prop.parcelid = txn.parcelid  -- using(parcelid)\n",
    "\n",
    "-- # 3:     \n",
    "join predictions_2017 as pred  on prop.parcelid = pred.parcelid and pred.transactiondate = txn.transactiondate -- using(parcelid, transactiondate)\n",
    "\n",
    "-- #4: left join otherwise we would have dropped a TON of rows due to all the nulls \n",
    "left join airconditioningtype as ac on prop.airconditioningtypeid = ac.airconditioningtypeid\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d56ed",
   "metadata": {},
   "source": [
    "/* i can verify we have the correct number of rows by wrapping the entire query in a count */\n",
    "\n",
    "select count(*) from \n",
    "(\n",
    "-- 2. next I selected 2 columns from the primary table (properties_2017) and inner joined with the txn date subquery\n",
    "\t\t\tselect \tprop.parcelid, \n",
    "\t\t\t\t\t\tprop.airconditioningtypeid,\n",
    "\t\t\t\t\t\tac.airconditioningdesc,-- 4. finally I did a left join with the airconditioning table to get the description. \n",
    "\t\t\t\t\t\ttxn.transactiondate, \n",
    "\t\t\t\t\t\tpred.logerror -- 3.i joined with the predictions table again to get the log error that is associated with the parcel AND transaction date\n",
    "\t\t\t\t\t\t-- (see join below labeled #3)\n",
    "\t\t\tfrom properties_2017 prop\n",
    "\t\t\tjoin \n",
    "\t\t\t\t(\n",
    "\t\t\t\t-- 1. this is what i did first...create a dataset with each parcelid and their last transaction date. \n",
    "\t\t\t\tselect parcelid, max(transactiondate) as transactiondate\n",
    "\t\t\t\tfrom predictions_2017\n",
    "\t\t\t\tgroup by parcelid\n",
    "\t\t\t\t) as txn on prop.parcelid = txn.parcelid  -- using(parcelid)\n",
    "\n",
    "\t\t\t-- # 3:     \n",
    "\t\t\tjoin predictions_2017 as pred  on prop.parcelid = pred.parcelid and pred.transactiondate = txn.transactiondate -- using(parcelid, transactiondate)\n",
    "\n",
    "\t\t\t-- #4: left join otherwise we would have dropped a TON of rows due to all the nulls \n",
    "\t\t\tleft join airconditioningtype as ac on prop.airconditioningtypeid = ac.airconditioningtypeid\n",
    ") AS a -- because subqueries need to be aliased. \n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b4887a",
   "metadata": {},
   "source": [
    "select * from predictions_2017\n",
    "where parcelid = 11721753;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
